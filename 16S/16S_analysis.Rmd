---
title: "R Notebook"
output: html_notebook
---


Update to R 4.

```{r}
BiocManager::install(version = '3.12')
```


#Step 1: Install dada2 from Bioconductor

```{r, echo=FALSE}
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("dada2", version = "3.12")
```

Install "phyloseq", "Biostrings", "ggplot2"

```{r}
BiocManager::install(c("phyloseq", "Biostrings", "ggplot2"))
```

#Step 2: Load the dada2 library


```{r}
library("dada2")
library("tictoc")
```

#Step 3: Set directory path containing the fastq files
These fastq files were generated by 2x250 Illumina Miseq amplicon sequencing of the V4 region of the 16S rRNA gene (for more information about the data refer to day 1 lecture). 

```{r}
tic()
path <- "/Users/pk7z/Desktop/BIOINFORMATICS-CORE/TUMI-COURSE-WORK/16S-data" # Change the path.
list.files(path)
toc()
```

#Step 4: Read the names of the fastq files, and perform some string manipulation to get matched lists of the forward and reverse fastq files.


```{r}
tic()
# Forward and reverse fastq filenames have format: SAMPLENAME_R1_001.fastq and SAMPLENAME_R2_001.fastq
fnFs <- sort(list.files(path, pattern="_R1_001.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_R1_001.fastq"), `[`, 1)
sample.names
toc()
```


#Step 5: Filter and trim the reads. Assign the filenames for the filtered fastq.gz files. The below step will creat a filtered sub-directory.


```{r}
tic()
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
toc()
```


#Step 6: 
#1) Filter out reads that has "N" after truncation, 
#2) allow upto two expected error (Expected errors are calculated from the nominal definition of the quality score: EE = sum(10^(-Q/10))), 
#3) truncQ=2 (Truncate reads at the first instance of a quality score less than or equal to truncQ),
#4) rm.phix=TRUE (discard reads that match against the phiX genome). 


```{r}
tic()
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(245,230), 
                     maxN=0, maxEE=c(2,3), truncQ=1, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
toc()
```


#Step 7: Learn the Error Rates
The learnErrors method learns this error model from the data, by alternating estimation of the error rates and inference of sample composition until they converge on a jointly consistent solution. As in many machine-learning problems, the algorithm must begin with an initial guess, for which the maximum possible error rates in this data are used (the error rates if only the most abundant sequence is correct and all the rest are errors).


```{r, fig.width =5, fig.height=2}
tic()
errF <- learnErrors(filtFs, multithread=TRUE)
errR <- learnErrors(filtRs, multithread=TRUE)
toc()
```

Make a plot


```{r, fig.width =3, fig.height=2}
tic()
plotErrors(errF, nominalQ=TRUE)
toc()
```
Figure Legend: The error rates for each possible transition (A→C, A→G, …) are shown. Points are the observed error rates for each consensus quality score. The black line shows the estimated error rates after convergence of the machine-learning algorithm. The red line shows the error rates expected under the nominal definition of the Q-score. Here the estimated error rates (black line) are a good fit to the observed rates (points), and the error rates drop with increased quality as expected. Everything looks reasonable and we proceed with confidence.

 
#Step 8: Sample Inference: Identify unique sequence and their frequency (filtered and trimmed sequence data)

R1 reads

```{r}
tic()
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
toc()
```

R2 reads

```{r}
tic()
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)
toc()
```


#Step 9:Merge paired reads 
We now merge the forward and reverse reads together to obtain the full denoised sequences. Merging is performed by aligning the denoised forward reads with the reverse-complement of the corresponding denoised reverse reads, and then constructing the merged “contig” sequences. By default, merged sequences are only output if the forward and reverse reads overlap by at least 12 bases, and are identical to each other in the overlap region (but these conditions can be changed via function arguments).

```{r}
tic()
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE, maxMismatch = 15)
toc()
```


```{r}
# Inspect the merger data.frame from the first sample
head(mergers[[1]])
```


#Step 10:Construct sequence table 
We can now construct an amplicon sequence variant table (ASV) table, a higher-resolution version of the OTU table produced by traditional methods.

```{r}
tic()
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
toc()
```

#Step 10:Plot length distribution of merged sequence

```{r, fig.width =4, fig.height=2}
# Inspect distribution of sequence lengths
plot(table(nchar(getSequences(seqtab))))
```


#Step 11: Remove chimeras 
The core dada method corrects substitution and indel errors, but chimeras remain. Fortunately, the accuracy of sequence variants after denoising makes identifying chimeric ASVs simpler than when dealing with fuzzy OTUs. Chimeric sequences are identified if they can be exactly reconstructed by combining a left-segment and a right-segment from two more abundant “parent” sequences.


```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
```


```{r, fig.width =4, fig.height=2}
plot(table(nchar(getSequences(seqtab.nochim))))
```


#Step 12:Track reads through the pipeline 
As a final check of our progress, we’ll look at the number of reads that made it through each step in the pipeline:

```{r, echo=FALSE}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))

colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
track
```


Write QC table to a file

```{r}
write.table(track, "/Users/pk7z/Desktop/BIOINFORMATICS-CORE/TUMI-COURSE-WORK/Data-QC-Summary-Table.txt")
```

```{r}
samples.out <- rownames(seqtab.nochim)
write.table(samples.out, "/Users/pk7z/Desktop/BIOINFORMATICS-CORE/TUMI-COURSE-WORK/sample-meta-data-onlyrow")
```


#Step 13: Assign taxonomy 
It is common in 16S amplicon sequencing, to assign taxonomy to the sequence variants. The DADA2 package provides a native implementation of the naive Bayesian classifier method for this purpose. The assignTaxonomy function takes as input a set of sequences to be classified and a training set of reference sequences with known taxonomy, and outputs taxonomic assignments with at least minBoot bootstrap confidence.

```{r}
tic()
taxa <- assignTaxonomy(seqtab.nochim, "/Users/pk7z/Desktop/BIOINFORMATICS-CORE/TUMI-COURSE-WORK/16S-data_training/silva_nr_v138_train_set.fa", multithread=TRUE)
toc()
```


#Step 14: Assign taxonomy (species level)
The dada2 package also implements a method to make species level assignments based on exact matching between ASVs and sequenced reference strains. 

```{r}
tic()
taxa <- addSpecies(taxa, "/Users/pk7z/Desktop/BIOINFORMATICS-CORE/TUMI-COURSE-WORK/16S-data_training/silva_species_assignment_v138.fa")
toc()
```

Checking ASV assignment

```{r}
tic()
taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
toc()
```


#Step 14: load phyloseq, Biostrings, ggplot2


```{r}
tic()
library(phyloseq); packageVersion("phyloseq")
library(Biostrings); packageVersion("Biostrings")
library(ggplot2); packageVersion("ggplot2")
toc()
```


#Step 15: Read in metadata file

```{r}
tic()
samdf <- read.table("/Users/pk7z/Desktop/BIOINFORMATICS-CORE/TUMI-COURSE-WORK/TUMI_16S_metadata.csv", header=T, sep="\t", row.names = 1)
samdf
toc()
```

#Step 16: Construct Phyloseq object
We now construct a phyloseq object directly from the dada2 outputs.

```{r}
tic()
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), 
               sample_data(samdf), 
               tax_table(taxa))
toc()
```


#Step 17: Construct Phyloseq object

It is more convenient to use short names for ASVs (e.g. ASV21) rather than the full DNA sequence when working with some of the tables and visualizations from phyloseq, but we want to keep the full DNA sequences for other purposes like merging with other datasets or indexing into reference databases like the Earth Microbiome Project. For that reason we’ll store the DNA sequences of our ASVs in the "refseq slot" of the phyloseq object, and then rename the taxa to a short string. That way, the short new taxa names will appear in tables and plots, and we can still recover the DNA sequences corresponding to each ASV as needed with refseq(ps).


```{r}
tic()
dna <- Biostrings::DNAStringSet(taxa_names(ps))
names(dna) <- taxa_names(ps)
ps <- merge_phyloseq(ps, dna)
taxa_names(ps) <- paste0("ASV", seq(ntaxa(ps)))
ps
toc()
```


#Step 18: Exporting OTU table from phyloseq object
At this momemt if you may wish you may export the OTU table


```{r}
tic()
# Extract abundance matrix from the phyloseq object
OTU1 = as(otu_table(ps), "matrix")
# transpose if necessary
if(taxa_are_rows(ps)){OTU1 <- t(OTU1)}
# Coerce to data.frame
OTUdf = as.data.frame(OTU1)
write.csv(OTUdf, "/Users/pk7z/Desktop/BIOINFORMATICS-CORE/TUMI-COURSE-WORK/TUMI_16S-OTU-Table.phyloseq.csv")
toc()
```



#Step 19: Visualize alpha-diversity:

```{r, fig.width =4, fig.height=2}
tic()
plot_richness(ps, x="Diet", measures=c("Observed", "Chao1", "ACE", "Shannon", "Simpson", "InvSimpson", "Fisher"),) 
toc()
```

#Comment: Obvious systematic difference in alpha-diversity between Control and Supplemented samples.

Same thing you may wish to plot as box-plot

```{r, fig.width =4, fig.height=2}
tic()
plot_richness(ps, x="Diet", measures=c("Observed", "Chao1", "ACE", "Shannon", "Simpson", "InvSimpson", "Fisher"),) + geom_boxplot()
toc()
```

#Richness estimate for calculating p-value

```{r}
tic()
rich = estimate_richness(ps)
rich
toc()
```

#Step 20: Calculate if the difference between two groups of samples are significant or not

Test whether the observed number of OTUs differs significantly between Sample_Type. We make a non-parametric test, the Wilcoxon rank-sum test (Mann-Whitney):

Observed

```{r}
tic()
pairwise.wilcox.test(rich$Observed, p.adjust.method = "bonferroni", sample_data(ps)$Diet, exact = FALSE)
toc()
```


Chao1

```{r, echo=FALSE}
tic()
pairwise.wilcox.test(rich$Chao1, p.adjust.method = "bonferroni", sample_data(ps)$Diet, exact = FALSE)
toc()
```

You may calculate the p-value for other alpha diversity.



#Step 21: Bar plot:

```{r, fig.width =4, fig.height=2}
tic()
top20 <- names(sort(taxa_sums(ps), decreasing=TRUE))[1:20]
ps.top20 <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top20 <- prune_taxa(top20, ps.top20)
plot_bar(ps.top20, x="SampleID", fill="Genus") + facet_wrap(~Diet, scales="free_x")
toc()
```

#If you wish to make plot based on Family

```{r, fig.width =4, fig.height=2}
tic()
top20 <- names(sort(taxa_sums(ps), decreasing=TRUE))[1:20]
ps.top20 <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top20 <- prune_taxa(top20, ps.top20)
plot_bar(ps.top20, x="SampleID", fill="Family") + facet_wrap(~Diet, scales="free_x")
toc()
```


#Step 22: Calcutale Ordinate

```{r}
tic()
# Transform data to proportions as appropriate for Bray-Curtis distances
ps.prop <- transform_sample_counts(ps, function(otu) otu/sum(otu))
ord.nmds.bray <- ordinate(ps.prop, method="NMDS", distance="bray")
toc()
```

#Step 23: Ordinate Plot

```{r, fig.width =4, fig.height=2}
tic()
plot_ordination(ps.prop, ord.nmds.bray, color="Diet", label = "SampleID", title="Bray NMDS")
toc()
```

#Ordination picks out a clear separation between the samples.

#Step 24: Beta diversity

```{r}
tic()
library("ape")
toc()
```

```{r}
random_tree = rtree(ntaxa(ps), rooted=TRUE, tip.label=taxa_names(ps))
```

```{r}
ps = merge_phyloseq(ps, samples.out, random_tree)
```

#Step 25: Plot the PCoA using the unweighted UniFrac as distance:

```{r, fig.width =3, fig.height=2}
tic()
# PCoA plot using the unweighted UniFrac as distance
wunifrac_dist = phyloseq::distance(ps, method="unifrac", weighted=F)
ordination = ordinate(ps.prop, method="PCoA", distance=wunifrac_dist)
plot_ordination(ps, ordination, color="Diet", label = "SampleID") + theme(aspect.ratio=1)
toc()
```


#Step 26: Plot Tree

```{r, fig.width =6, fig.height=9}
plot_tree(ps, color="Diet", label.tips="Genus", size="abundance", plot.margin=0.2, text.size = 2)
```


This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

```{r}
sessionInfo()
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

